 gcloud config set project kafka-demo-441512

gcloud container clusters create kafka-cluster --region asia-south1 --num-nodes=2

low grade machine with hdd
gcloud container clusters create kafka-cluster \
--region us-central1 \
--num-nodes=2 \
--machine-type=e2-micro \
--disk-type=pd-standard \
--disk-size=100GB



gcloud container clusters create kafka-cluster \
--region asia-south1 \
--num-nodes=3 \
--machine-type=e2-standard-2 \
--disk-type=pd-standard \
--disk-size=100GB

kubectl run kafka-client --image=confluentinc/cp-kafka:latest --namespace=kafka --command -- sleep infinity
List Kafka Topics:
kubectl exec -it kafka-client --namespace=kafka -- kafka-topics --list --bootstrap-server kafka:9092

command to create topic 
root@sumanpc:/mnt/c/Users/ciphe/Projects/gke-kafka/kafka-demo# kubectl exec -it kafka-client --namespace=kafka -- kafka-topics --create --topic test-topic --bootstrap-server kafka-svc:9092 --partitions 3 --replication-factor 1


helm install zookeeper bitnami/zookeeper \
  --namespace kafka \
  --set replicaCount=3 \
  --set persistence.enabled=true \
  --set persistence.size=10Gi

  docker build -t gcr.io/eighth-codex-439113-s2/container-app:latest .
  




root@sumanpc:~# kubectl get pods -n kafka -l app.kubernetes.io/name=zookeeper
NAME          READY   STATUS    RESTARTS   AGE
zookeeper-0   1/1     Running   0          2m45s
zookeeper-1   1/1     Running   0          2m45s
zookeeper-2   1/1     Running   0          2m45s


kafka-topics.sh --create --zookeeper zookeeper.kafka.svc.cluster.local:2181 --replication-factor 3 --partitions 6 --topic my-topic

kafka-topics.sh --create --bootstrap-server kafka-controller-headless.kafka.svc.cluster.local:9094 --replication-factor 3 --partitions 6 --topic my-topic

root@sumanpc:/mnt/c/Users/ciphe/Projects/gke-kafka/kafka-demo# helm upgrade --install kafka bitnami/kafka -f values.yaml -n kafka
Release "kafka" has been upgraded. Happy Helming!
NAME: kafka
LAST DEPLOYED: Wed Nov 13 01:32:18 2024
NAMESPACE: kafka
STATUS: deployed
REVISION: 2
TEST SUITE: None
NOTES:
CHART NAME: kafka
CHART VERSION: 31.0.0
APP VERSION: 3.9.0

** Please be patient while the chart is being deployed **

Kafka can be accessed by consumers via port 9092 on the following DNS name from within your cluster:

    kafka.kafka.svc.cluster.local

Each Kafka broker can be accessed by producers via port 9092 on the following DNS name(s) from within your cluster:

    kafka-controller-0.kafka-controller-headless.kafka.svc.cluster.local:9092
    kafka-controller-1.kafka-controller-headless.kafka.svc.cluster.local:9092
    kafka-controller-2.kafka-controller-headless.kafka.svc.cluster.local:9092

The CLIENT listener for Kafka client connections from within your cluster have been configured with the following security settings:
    - SASL authentication

To connect a client to your Kafka, you need to create the 'client.properties' configuration files with the content below:

security.protocol=SASL_PLAINTEXT
sasl.mechanism=SCRAM-SHA-256
sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
    username="user1" \
    password="$(kubectl get secret kafka-user-passwords --namespace kafka -o jsonpath='{.data.client-passwords}' | base64 -d | cut -d , -f 1)";

To create a pod that you can use as a Kafka client run the following commands:

    kubectl run kafka-client --restart='Never' --image docker.io/bitnami/kafka:3.9.0-debian-12-r1 --namespace kafka --command -- sleep infinity
    kubectl cp --namespace kafka /path/to/client.properties kafka-client:/tmp/client.properties
    kubectl exec --tty -i kafka-client --namespace kafka -- bash

    PRODUCER:
        kafka-console-producer.sh \
            --producer.config /tmp/client.properties \
            --bootstrap-server kafka.kafka.svc.cluster.local:9092 \
            --topic test

    CONSUMER:
        kafka-console-consumer.sh \
            --consumer.config /tmp/client.properties \
            --bootstrap-server kafka.kafka.svc.cluster.local:9092 \
            --topic test \
            --from-beginning

WARNING: There are "resources" sections in the chart not set. Using "resourcesPreset" is not recommended for production. For production installations, please set the following values according to your workload needs:
  - controller.resources
+info https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
root@sumanpc:/mnt/c/Users/ciphe/Projects/gke-kafka/kafka-demo#


lets focus on 
https://cloud.google.com/kubernetes-engine/docs/tutorials/stateful-workloads/confluent


gcloud projects add-iam-policy-binding PROJECT_ID --member="user:USER_IDENTIFIER" --role=ROLE

sumang.codes@gmail.com

kafka-demo-441512


gcloud projects add-iam-policy-binding kafka-demo-441512 --member="user:sumang.codes@gmail.com" --role=roles/storage.objectViewer

roles/logging.logWriter


gcloud projects add-iam-policy-binding kafka-demo-441512 --member="user:sumang.codes@gmail.com" --role=roles/logging.logWriter

roles/container.clusterAdmin

gcloud projects add-iam-policy-binding kafka-demo-441512 --member="user:sumang.codes@gmail.com" --role=roles/container.clusterAdmin

roles/container.serviceAgent

gcloud projects add-iam-policy-binding kafka-demo-441512 --member="user:sumang.codes@gmail.com" --role=roles/container.serviceAgent


export PROJECT_ID=PROJECT_ID

export PROJECT_ID=kafka-demo-441512

command to create topic 
sh kafka-topics.sh --create \
  --bootstrap-server 34.93.22.146:9095 \
  --command-config client.properties \
  --topic sumantopic \
  --partitions 3 \
  --replication-factor 1
